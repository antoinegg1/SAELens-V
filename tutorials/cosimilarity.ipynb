{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab # type: ignore\n",
    "    from google.colab import output\n",
    "    COLAB = True\n",
    "    %pip install sae-lens transformer-lens\n",
    "except:\n",
    "    COLAB = False\n",
    "    from IPython import get_ipython # type: ignore\n",
    "    ipython = get_ipython(); assert ipython is not None\n",
    "    ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
    "    ipython.run_line_magic(\"autoreload\", \"2\")\n",
    "\n",
    "# Standard imports\n",
    "import os\n",
    "import torch\n",
    "import tqdm\n",
    "import plotly.express as px  \n",
    "import random\n",
    "from datasets import Dataset, DatasetDict, IterableDataset, load_dataset,load_from_disk\n",
    "from transformer_lens import HookedTransformer\n",
    "from typing import Any, Generator, Iterator, Literal, cast\n",
    "from sae_lens import SAE\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    LlavaNextForConditionalGeneration,\n",
    "    LlavaNextProcessor,\n",
    "    AutoModelForCausalLM,\n",
    ")\n",
    "import numpy as np\n",
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:7890\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:7890\"\n",
    "import concurrent.futures\n",
    "from transformer_lens.HookedLlava import HookedLlava\n",
    "from sae_lens.activation_visualization import (\n",
    "    load_llava_model,\n",
    "    load_sae,\n",
    "    separate_feature,\n",
    "    run_model,\n",
    "    cal_top_cosimilarity,\n",
    ")\n",
    "\n",
    "model_name = \"llava-hf/llava-v1.6-mistral-7b-hf\"\n",
    "model_path=\"/data/models/llava-v1.6-mistral-7b-hf\"\n",
    "sae_path=\"/data/changye/model/llavasae_obliec100k_SAEV\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b03144303b94181b369e21232dec2be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization check time: 0.00s\n",
      "Configuration loading time: 0.00s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faefd9d9498c4998bddb6dcc59e2116e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model configuration processing time: 1.16s\n",
      "State dict loading time: 0.02s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc531f63f734398a7aa86f71fbbd8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54da214870c4b2fb9c74ffae15ee738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce9544f0ade4a1d9e34cb4f5b59971f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f571bdb122b4d64a7bc482ab9f96c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/41.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6098015970af4252b24cb37539e318b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer setup time: 5.00s\n",
      "Embedding setup time: 65.93s\n",
      "Move device time: 0.00s\n",
      "Set up time: 0.00s\n",
      "Model creation time: 70.94s\n",
      "State dict processing time: 31.23s\n",
      "Device moving time: 13.26s\n",
      "Total loading time: 116.61s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/changye/SAELens-V/sae_lens/sae.py:136: UserWarning: \n",
      "This SAE has non-empty model_from_pretrained_kwargs. \n",
      "For optimal performance, load the model like so:\n",
      "model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6,7\" \n",
    "sae_device=\"cuda:7\"\n",
    "device=\"cuda:0\"\n",
    "processor,  hook_language_model = load_llava_model(\n",
    "        model_name, model_path, device,n_devices=8,stop_at_layer=17\n",
    "    )\n",
    "sae = load_sae(sae_path, sae_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['ds_name', 'image', 'question', 'chosen', 'rejected', 'origin_dataset', 'origin_split', 'idx', 'image_path'],\n",
      "    num_rows: 1000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#1.通过采样集给sae feature 评分\n",
    "## 1.1 读取采样集\n",
    "dataset_path=\"/data/changye/data/RLAIF-V-Dataset1k\"\n",
    "system_prompt= \" \"\n",
    "user_prompt= 'USER: \\n<image> {input}'\n",
    "assistant_prompt= '\\nASSISTANT: {output}'\n",
    "split_token= 'ASSISTANT:' \n",
    "eval_dataset = load_from_disk(\n",
    "            dataset_path,\n",
    "        )\n",
    "\n",
    "total_size = len(eval_dataset)\n",
    "\n",
    "print(eval_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 1000/1000 [32:29<00:00,  1.95s/it] \n"
     ]
    }
   ],
   "source": [
    "## 1.2 组合input\n",
    "\n",
    "def prepare_inputs(i,formatted_sample,processor):\n",
    "    prompt=formatted_sample['question'][i]\n",
    "    formatted_prompt = f'{system_prompt}{user_prompt.format(input=prompt)}{assistant_prompt.format(output=\"\")}'\n",
    "    image = formatted_sample['image'][i]\n",
    "    image = image.resize((336, 336)).convert('RGBA')\n",
    "    \"\"\"处理样本并准备输入\"\"\"\n",
    "    return processor(\n",
    "        text=formatted_prompt,\n",
    "        images=image,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "inputs=[]\n",
    "with tqdm.tqdm(total=total_size, desc=\"Processing batches\") as pbar:\n",
    "        max_threads = 60  # 设置你希望的线程数，可以根据需要调整\n",
    "        # print(\"os cpu counts\",os.cpu_count())\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "            futures = []\n",
    "            # 提交所有任务到线程池\n",
    "            for i in range(0, total_size):\n",
    "                future = executor.submit(prepare_inputs, \n",
    "                                        i, \n",
    "                                        eval_dataset, \n",
    "                                        processor, \n",
    "                                       )\n",
    "                futures.append(future)\n",
    "\n",
    "            # 使用 as_completed 确保任务完成后及时更新进度条\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                input = future.result()  # 获取每个批次处理后的结果\n",
    "                inputs.append(input)  # 将处理的结果添加到 all_inputs\n",
    "                pbar.update(1)  # 更新进度条\n",
    "                pbar.refresh()  # 强制刷新进度条，确保显示更新\n",
    "    \n",
    "# print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for input in inputs:\n",
    "# tmp_cache,image_indices, feature_act = run_model(inputs[0], hook_language_model, sae, sae_device,stop_at_layer=17)\n",
    "# print(tmp_cache.shape)\n",
    "# print(image_indices.shape)\n",
    "# print(feature_act.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing cosimilarity: 100%|██████████| 1000/1000 [46:20<00:00,  2.78s/it] \n"
     ]
    }
   ],
   "source": [
    "text_token_meta_list=[]\n",
    "image_token_meta_list=[]\n",
    "with tqdm.tqdm(total=len(inputs), desc=\"Processing cosimilarity\") as pbar:\n",
    "    for input in inputs:\n",
    "        tmp_cache,image_indices, feature_act = run_model(input, hook_language_model, sae, sae_device,stop_at_layer=17)\n",
    "        # print(image_indices.shape)\n",
    "        text_token_list, image_token_list=cal_top_cosimilarity(tmp_cache[0],image_indices[0], feature_act[0])\n",
    "        text_token_meta_list.append(text_token_list)\n",
    "        image_token_meta_list.append(image_token_list)\n",
    "        pbar.update(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_sliced_pt(data_list, output_folder, file_prefix, slice_size):\n",
    "#     \"\"\"\n",
    "#     将大列表切分成多个小文件保存为 .pt 格式。\n",
    "    \n",
    "#     参数:\n",
    "#     - data_list: 待保存的列表。\n",
    "#     - output_folder: 输出文件夹路径。\n",
    "#     - file_prefix: 保存文件的前缀名。\n",
    "#     - slice_size: 每个小文件的最大元素数。\n",
    "#     \"\"\"\n",
    "#     os.makedirs(output_folder, exist_ok=True)  # 确保文件夹存在\n",
    "    \n",
    "#     num_slices = (len(data_list) + slice_size - 1) // slice_size  # 计算分片数量\n",
    "#     for i in range(num_slices):\n",
    "#         start_idx = i * slice_size\n",
    "#         end_idx = min((i + 1) * slice_size, len(data_list))\n",
    "#         slice_data = data_list[start_idx:end_idx]\n",
    "        \n",
    "#         # 构造文件名\n",
    "#         file_path = os.path.join(output_folder, f\"{file_prefix}_part_{i + 1}.pt\")\n",
    "#         torch.save(slice_data, file_path)\n",
    "#         print(f\"Saved slice {i + 1} to {file_path}\")\n",
    "\n",
    "# # 假设你已经准备好了 `flattened_text_list` 和 `flattened_image_list`\n",
    "flattened_text_list = np.concatenate(text_token_meta_list).tolist()\n",
    "flattened_image_list = np.concatenate(image_token_meta_list).tolist()\n",
    "\n",
    "# # 设置保存参数\n",
    "# output_folder = \"/data/changye/output_folder_path\"  # 替换为实际路径\n",
    "# text_prefix = \"flattened_text_list\"\n",
    "# image_prefix = \"flattened_image_list\"\n",
    "# slice_size = 50000  # 每个文件保存 10000 条数据\n",
    "\n",
    "# # 保存分片的文件\n",
    "# save_sliced_pt(flattened_text_list, output_folder, text_prefix, slice_size)\n",
    "# save_sliced_pt(flattened_image_list, output_folder, image_prefix, slice_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing flattened_text_list: 100%|██████████| 26395/26395 [01:31<00:00, 289.00it/s] \n",
      "Processing flattened_image_list: 100%|██████████| 1176000/1176000 [22:35<00:00, 867.72it/s] \n",
      "Processing feature_num: 100%|██████████| 65536/65536 [02:08<00:00, 508.18it/s]\n"
     ]
    }
   ],
   "source": [
    "#我现在有两个list,flattened_text_list和flattend_image_list,他们的每个元素,称之为token都包含两个字典dict_keys(['features', 'logits']),其中features这个key对应的value也是一个字典,它的key为feature_index,value为feature_activation_value,\n",
    "#现在我希望对每个feature对照一个排序,每个feature要排序出它激活值最高的30个token(假设features中的子字典没有这个feature的index,则说明它在该token的激活值为0),并且能够区分哪些token是text的,哪些是image的.请补全以下代码:\n",
    "feature_num = 65536  # 定义特征的总数量\n",
    "features_top = [[] for _ in range(feature_num)]  # 初始化每个特征的列表，用于存储对应的 tokens\n",
    "\n",
    "# 处理文本 tokens\n",
    "with tqdm.tqdm(total=len(flattened_text_list), desc=\"Processing flattened_text_list\") as pbar:\n",
    "    for token in flattened_text_list:\n",
    "        for feature_index, activation_value in token['features'].items():\n",
    "            # 将激活值、token 和类型 ('text') 添加到对应特征的列表中\n",
    "            features_top[feature_index].append((activation_value, token, 'text'))\n",
    "        pbar.update(1)\n",
    "        pbar.refresh()\n",
    "\n",
    "# 处理图像 tokens\n",
    "with tqdm.tqdm(total=len(flattened_image_list), desc=\"Processing flattened_image_list\") as pbar:\n",
    "    for token in flattened_image_list:\n",
    "        for feature_index, activation_value in token['features'].items():\n",
    "            # 将激活值、token 和类型 ('image') 添加到对应特征的列表中\n",
    "            features_top[feature_index].append((activation_value, token, 'image'))\n",
    "        pbar.update(1)\n",
    "        pbar.refresh()\n",
    "\n",
    "# 对每个特征进行排序并选取激活值最高的 30 个 tokens\n",
    "with tqdm.tqdm(total=feature_num, desc=\"Processing feature_num\") as pbar:\n",
    "    for i in range(feature_num):\n",
    "        tokens_with_activation = features_top[i]\n",
    "        if tokens_with_activation:\n",
    "            # 按激活值从大到小排序\n",
    "            tokens_with_activation.sort(key=lambda x: x[0], reverse=True)\n",
    "            # 选取前 30 个激活值最高的 tokens\n",
    "            features_top[i] = tokens_with_activation[:30]\n",
    "        else:\n",
    "            # 如果没有对应的 tokens，设为空列表\n",
    "            features_top[i] = []\n",
    "        pbar.update(1)\n",
    "        pbar.refresh()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing feature_num:  48%|████▊     | 31500/65536 [00:37<00:40, 849.19it/s] \n"
     ]
    }
   ],
   "source": [
    "text_feature_list = []  # 存储所有 tokens 均为文本的特征索引\n",
    "image_feature_list = []  # 存储所有 tokens 均为图像的特征索引\n",
    "cosi_feature_list = []  # 存储同时包含文本和图像 tokens 的特征索引及其平均余弦相似度\n",
    "\n",
    "# 遍历每个特征\n",
    "with tqdm.tqdm(total=feature_num, desc=\"Processing feature_num\") as pbar:\n",
    "    for i in range(feature_num):\n",
    "        tokens = features_top[i]  # 获取特征 i 对应的 tokens 列表\n",
    "        if not tokens:\n",
    "            continue  # 如果没有 tokens，跳过该特征\n",
    "\n",
    "        # 分别存储文本和图像 tokens\n",
    "        text_tokens = []\n",
    "        image_tokens = []\n",
    "\n",
    "        for activation_value, token, token_type in tokens:\n",
    "            if token_type == 'text':\n",
    "                text_tokens.append((activation_value, token))\n",
    "            elif token_type == 'image':\n",
    "                image_tokens.append((activation_value, token))\n",
    "\n",
    "        # 判断特征类型并分类\n",
    "        if len(text_tokens) == len(tokens):\n",
    "            # 如果所有 tokens 均为文本\n",
    "            text_feature_list.append(i)\n",
    "        elif len(image_tokens) == len(tokens):\n",
    "            # 如果所有 tokens 均为图像\n",
    "            image_feature_list.append(i)\n",
    "        else:\n",
    "            # 同时包含文本和图像 tokens\n",
    "            if len(text_tokens) >= 5 and len(image_tokens) >= 5:\n",
    "                # 取前 5 个激活值最高的文本和图像 tokens\n",
    "                top_text_tokens = text_tokens[:5]\n",
    "                top_image_tokens = image_tokens[:5]\n",
    "\n",
    "                # 提取 logits\n",
    "                text_logits = [token['logits'] for _, token in top_text_tokens]\n",
    "                image_logits = [token['logits'] for _, token in top_image_tokens]\n",
    "\n",
    "                # 计算每个文本 logits 与每个图像 logits 的余弦相似度，并取平均值\n",
    "                cosine_similarities = []\n",
    "                for t_logit in text_logits:\n",
    "                    for i_logit in image_logits:\n",
    "                        # 确保 logits 是 numpy 数组\n",
    "                        t_logit = np.array(t_logit)\n",
    "                        i_logit = np.array(i_logit)\n",
    "\n",
    "                        # 计算余弦相似度\n",
    "                        numerator = np.dot(t_logit, i_logit)\n",
    "                        denominator = np.linalg.norm(t_logit) * np.linalg.norm(i_logit)\n",
    "                        if denominator == 0:\n",
    "                            cosine_similarity = 0\n",
    "                        else:\n",
    "                            cosine_similarity = numerator / denominator\n",
    "                        cosine_similarities.append(cosine_similarity)\n",
    "\n",
    "                # 计算平均余弦相似度\n",
    "                average_cosine_similarity = np.mean(cosine_similarities)\n",
    "\n",
    "                # 将特征索引和平均余弦相似度添加到列表\n",
    "                cosi_feature_list.append((i, average_cosine_similarity))\n",
    "        pbar.update(1)\n",
    "        pbar.refresh()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/changye/data/RLAIF-V_interp/RLAIF-V_cosi_weight/text_feature_list.txt', 'w') as f:\n",
    "    for feature_index in text_feature_list:\n",
    "        f.write(f\"{feature_index}\\n\")\n",
    "\n",
    "# 保存 image_feature_list\n",
    "with open('/data/changye/data/RLAIF-V_interp/RLAIF-V_cosi_weight/image_feature_list.txt', 'w') as f:\n",
    "    for feature_index in image_feature_list:\n",
    "        f.write(f\"{feature_index}\\n\")\n",
    "\n",
    "# 保存 cosi_feature_list\n",
    "with open('/data/changye/data/RLAIF-V_interp/RLAIF-V_cosi_weight/cosi_feature_list.txt', 'w') as f:\n",
    "    for feature_index, average_cosine_similarity in cosi_feature_list:\n",
    "        f.write(f\"{feature_index},{average_cosine_similarity}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
